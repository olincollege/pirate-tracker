{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Pirate Booty\n",
    "authors: Hong Zhang, Samuel Bloom\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction** ##\n",
    "<hr>\n",
    "This project takes all the pirate attacks over the course of a year and analyzes them based on location and description. Based on these attributes, we can decipher the results of many pirate attacks, which areas are most susceptible, and better understand what specifically drives pirates to steal certain materials.\n",
    "\n",
    "By using online resources (data found through APIs and PDFs), we can visualize the pirate attacks across the globe, what results typically spur from pirate attacks, and much of the nature of piracy. Using nearby port exports and imports, we can further understand what specifically pirates are stealing, and if they are related to many of the goods these ships are carrying.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{python}\n",
    "pip install -r ~/pirate-tracker/Home/requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geodatasets\n",
    "import geopandas\n",
    "import matplotlib\n",
    "import pandas\n",
    "import pdfplumber\n",
    "import regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, make sure to run the code below to complete functionality of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Methodology**\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing Pirate Attacks Across the Globe** ###\n",
    "Through the usage of online resources, we were able to find both an API that will allow us to collect information on various port data (exports and imports), and also found a PDF from online (https://www.recaap.org/) that provided us with information on pirate attacks over the course of the 2024 year. Given this information, we were able to use an online library, `fitz`, to help digest this information. This online library helps process text block by block, in favor a line by line solution. This is important because it allows us to help analyze the **description** of the function by testing different phrases against it (*a later problem*).\n",
    "\n",
    "By processing the data through a function that calls `fitz`, `regex`, and `pandas` - libraries of which digest text, analyze structure, and sort into dataframes respectively - we were provided with `pirate_locations.csv`. The columns of the CSV are as follows:\n",
    "\n",
    "* Index of Incident\n",
    "* Latitude\n",
    "* Longitude \n",
    "* Area Location\n",
    "\n",
    "Given this CSV file, of which contains **107 entries**, we can then store these dataframes in empty lists and run operations over said lists. For example, we had to prepare our latitude and longitude data through conversions of **DMS** format (direction, minute, seconds) to degrees, a value that is easier to process and plot. Through this conversion, and accessing an online library through a variety of online libraries - `Geopandas`, `Geodatasets`, `Shapely`, some of the previous libraries accessed (`regex`) - we were then able to visualize our specific pirate attack incidents over a world map. Given this same data, we had also specifically zoomed in on areas around Southeast Asia, a hotspot for real-world piracy for further context.\n",
    "\n",
    "**P.S. If you are interested in learning about what the specific functions do, look to the docstrings where each libraries usage is explained**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing Phrases Associated with the Outcomes of Real-World Piracy** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results** #\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the completed functions, and libraries all downloaded/imported from `requirements.txt`, we can visualize all of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Interpretation** #\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 contextual phrases:\n",
      "\"the crew was not injured\": 36\n",
      "\"crew members were accounted for\": 20\n",
      "\"all crew members were accounted\": 19\n",
      "\"sighted in the engine room\": 17\n",
      "\"were sighted in the engine\": 16\n",
      "\"crew mustered to conduct a\": 15\n",
      "\"in the engine room the\": 15\n",
      "\"crew was not injured the\": 15\n",
      "\"all crew mustered to conduct\": 11\n",
      "\"and all crew mustered to\": 10\n",
      "\"all crew members were safe\": 10\n",
      "\"the engine room the master\": 9\n",
      "\"stolen the master reported the\": 9\n",
      "\"engine room the master raised\": 9\n",
      "\"was raised and all crew\": 9\n",
      "\"alarm was raised and crew\": 9\n",
      "\"raised and all crew mustered\": 9\n",
      "\"engine spare parts were stolen\": 8\n",
      "\"alarm and mustered the crew\": 8\n",
      "\"was not injured the master\": 8\n"
     ]
    }
   ],
   "source": [
    "from phrase_counter import extract_top_contextual_phrases\n",
    "\n",
    "df = extract_top_contextual_phrases(\"incident_descriptions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.7)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your phrase count data (from your loop result)\n",
    "phrase_counts = {\n",
    "    \"not injured\": 38,\n",
    "    \"nothing was stolen\": 24,\n",
    "    \"were accounted for\": 22,\n",
    "    \"no further assistance was required\": 10,\n",
    "    \"parts were stolen\": 10,\n",
    "    \"was safe\": 4,\n",
    "    \"were reported stolen\": 3,\n",
    "    \"no injuries were reported\": 2,\n",
    "    \"no property stolen\": 1,\n",
    "    \"nothing was reported stolen\": 1,\n",
    "    \"no property was stolen\": 0\n",
    "}\n",
    "\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white'\n",
    ").generate_from_frequencies(phrase_counts)\n",
    "\n",
    "# Display it using matplotlib\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Phrase Cloud Based on Incident Reports\", fontsize=16)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
